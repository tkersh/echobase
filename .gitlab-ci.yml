# GitLab CI/CD Pipeline for Echobase
# Designed for devlocal machine deployment with GitLab Runner (Docker Executor)

# Stages define the order of execution
stages:
  - validate       # Code validation and linting
  - build          # Build Docker images
  - durable        # Setup durable infrastructure (databases)
  - deploy-target  # Deploy to target environment for testing
  - test           # Run all tests (including tests against target)
  - promote        # Promote tested environment to production
  - teardown       # Manual teardown/cleanup stage

# Global variables
variables:
  # Docker Configuration
  DOCKER_HOST: unix:///var/run/docker.sock
  COMPOSE_PROJECT_NAME: echobase
  DOCKER_BUILDKIT: 1
  COMPOSE_DOCKER_CLI_BUILD: 1

  # Terraform Configuration
  TF_IN_AUTOMATION: "true"
  TF_INPUT: "false"

  # Test Configuration
  PLAYWRIGHT_BROWSERS_PATH: "$CI_PROJECT_DIR/.cache/ms-playwright"

  # Deployment Configuration
  DEPLOYMENT_ENV: "local"

  # CI/CD Flags
  GIT_STRATEGY: clone
  GIT_DEPTH: "1"

  # Network Configuration
  LOCALHOST_IP: "127.0.0.1"

  # Health Check Configuration
  HEALTH_CHECK_INTERVAL: "3"        # Seconds between health checks
  MARIADB_TIMEOUT: "120"            # MariaDB startup timeout in seconds
  LOCALSTACK_TIMEOUT: "150"         # LocalStack startup timeout in seconds
  API_GATEWAY_TIMEOUT: "120"        # API Gateway startup timeout in seconds
  FRONTEND_TIMEOUT: "90"            # Frontend startup timeout in seconds
  ORDER_PROCESSOR_TIMEOUT: "60"     # Order Processor startup timeout in seconds

  # Dev-Local Environment Ports (via start.sh)
  # These are used by docker-compose.override.yml
  DEV_LOCAL_API_PORT: "3001"
  DEV_LOCAL_FRONTEND_PORT: "3443"
  DEV_LOCAL_DB_PORT: "3306"
  DEV_LOCAL_LOCALSTACK_PORT: "4566"

  # Green Environment Ports (docker-compose.green.yml) - CI Canary
  # Can coexist with blue and devlocal
  GREEN_API_PORT: "3101"
  GREEN_FRONTEND_PORT: "3543"
  GREEN_DB_PORT: "3406"
  GREEN_LOCALSTACK_PORT: "4666"

  # Blue Environment Ports (docker-compose.blue.yml) - CI Production/Canary
  # Can coexist with green and devlocal
  # Note: Blue and Green share the CI durable database (no separate DB port)
  BLUE_API_PORT: "3102"
  BLUE_FRONTEND_PORT: "3544"
  BLUE_LOCALSTACK_PORT: "4667"

# Default settings for all jobs
default:
  artifacts:
    expire_in: 2 days
  image: docker:24
  tags:
    - docker-local  # Tag for your local GitLab runner with Docker executor
  before_script:
    - apk add --no-cache bash curl git docker-cli-compose nodejs npm openssl iproute2
  retry:
    max: 1
    when:
      - runner_system_failure
      - stuck_or_timeout_failure

# Cache configuration for dependencies
.cache_node_modules: &cache_node_modules
  cache:
    key: ${CI_COMMIT_REF_SLUG}-node-modules
    paths:
      - .npm/
      - backend/api-gateway/node_modules/
      - backend/order-processor/node_modules/
      - frontend/node_modules/
      - e2e-tests/node_modules/
    policy: pull

# Common before_script patterns
.install_terraform: &install_terraform
  - echo "Installing Terraform..."
  - curl -LO https://releases.hashicorp.com/terraform/1.14.2/terraform_1.14.2_linux_amd64.zip
  - unzip -o terraform_1.14.2_linux_amd64.zip -d /usr/local/bin/
  - chmod +x /usr/local/bin/terraform
  - terraform --version

.setup_scripts: &setup_scripts
  - chmod +x scripts/*.sh

.terraform_job_setup: &terraform_job_setup
  before_script:
    - apk add --no-cache bash curl git docker-cli-compose nodejs npm openssl unzip
    - *install_terraform
    - *setup_scripts

# ============================================================================
# VALIDATE STAGE
# ============================================================================

validate:env-check:
  stage: validate
  script:
    - echo "Checking environment prerequisites..."
    - docker --version
    - docker compose version
    - node --version
    - npm --version
    - echo "Generating .env file for CI..."
    - ./generate-credentials.sh
    - echo "Verifying .env file was created..."
    - test -f .env || (echo "ERROR - .env file generation failed!" && exit 1)

    # Configure environment for CI with Docker network
    - echo "Configuring environment for CI..."
    - sed -i "s|CORS_ORIGIN=.*|CORS_ORIGIN=https://localhost:${GREEN_FRONTEND_PORT}|g" .env
    # REACT_APP_API_URL should be empty - frontend uses same-origin and nginx proxies to backend
    - sed -i "s|REACT_APP_API_URL=.*|REACT_APP_API_URL=|g" .env
    - sed -i 's|RATE_LIMIT_MAX_REQUESTS=.*|RATE_LIMIT_MAX_REQUESTS=100000|g' .env
    - sed -i 's|RATE_LIMIT_WINDOW_MS=.*|RATE_LIMIT_WINDOW_MS=900000|g' .env
    - echo "CI-specific configuration:"
    - grep -E "(CORS_ORIGIN|REACT_APP_API_URL|RATE_LIMIT)" .env

    - echo "Environment check passed!"
  artifacts:
    paths:
      - .env
      - mariadb/config/
    expire_in: 1 hour
  only:
    - branches
    - merge_requests

validate:terraform:
  stage: validate
  before_script:
    - apk add --no-cache bash curl git docker-cli-compose nodejs npm openssl unzip
    - *install_terraform
  script:
    - echo "Validating Terraform configuration..."
    - cd terraform
    - terraform init -backend=false
    - terraform validate
    - terraform fmt -check -recursive
    - echo "Terraform validation passed!"
  only:
    - branches
    - merge_requests

validate:compose:
  stage: validate
  variables:
    GIT_STRATEGY: clone
    GIT_CLEAN_FLAGS: -ffdx
  tags:
    - docker-local
  script:
    - echo "Validating Docker Compose configuration..."
    # Create minimal .env file for validation
    - |
      cat > .env <<EOF
      MYSQL_ROOT_PASSWORD=test
      MYSQL_DATABASE=test_db
      MYSQL_USER=testuser
      MYSQL_PASSWORD=testpass
      PORT=3001
      AWS_REGION=us-east-1
      AWS_ACCESS_KEY_ID=test
      AWS_SECRET_ACCESS_KEY=test
      SQS_ENDPOINT=http://localhost:4566
      SQS_QUEUE_URL=http://localhost:4566/queue/test
      DB_SECRET_NAME=test
      JWT_SECRET=test
      CORS_ORIGIN=http://localhost:3000
      RATE_LIMIT_WINDOW_MS=60000
      RATE_LIMIT_MAX_REQUESTS=100
      DB_HOST=localhost
      DB_PORT=3306
      DB_NAME=test_db
      POLL_INTERVAL=5000
      MAX_MESSAGES=10
      REACT_APP_API_URL=http://localhost:3001
      EOF
    - docker compose config > /dev/null
    - echo "Docker Compose configuration is valid!"
  only:
    - branches
    - merge_requests

# ============================================================================
# BUILD STAGE
# ============================================================================

build:dependencies:
  stage: build
  <<: *cache_node_modules
  cache:
    policy: pull-push
  script:
    - echo "Installing Node.js dependencies..."
    - npm config set cache $CI_PROJECT_DIR/.npm --global
    - |
      # Install dependencies for all components
      for component in backend/api-gateway backend/order-processor frontend e2e-tests; do
        echo "Installing dependencies for ${component}..."
        (cd "$component" && npm ci --prefer-offline --no-audit)
      done
    - echo "All dependencies installed successfully!"
  artifacts:
    paths:
      - backend/api-gateway/node_modules/
      - backend/order-processor/node_modules/
      - frontend/node_modules/
      - e2e-tests/node_modules/
    expire_in: 1 hour
  only:
    - branches
    - merge_requests

build:docker-images:
  stage: build
  tags:
    - docker-local
  before_script:
    - apk add --no-cache bash docker-cli-compose
    - *setup_scripts
    - docker info
  dependencies:
    - build:dependencies
    - validate:env-check
  needs:
    - build:dependencies
    - validate:env-check
  script:
    - echo "Building Docker images..."
    - source .env

    # Set build metadata for Docker images (using GitLab CI predefined variables)
    - export GIT_SHORT_SHA=${CI_COMMIT_SHORT_SHA}
    - export BUILD_DATE=${CI_COMMIT_TIMESTAMP}
    - echo "Build metadata:"
    - echo "  GIT_SHORT_SHA=${GIT_SHORT_SHA}"
    - echo "  BUILD_DATE=${BUILD_DATE}"
    - echo "  CI_PIPELINE_ID=${CI_PIPELINE_ID}"

    # Clean up any stale BuildKit cache to avoid snapshot errors
    - echo "Cleaning BuildKit cache..."
    - docker builder prune -f --filter "until=24h" || true

    - echo "Building base image..."
    - docker build -t echobase-node-base:latest docker/base/

    # Build images without starting services (build args will be picked up from env vars)
    - docker compose build --parallel

    - echo "Docker images built successfully!"
    - docker images | grep echobase || echo "Images built"

    # Verify build metadata was included in images
    - scripts/verify-build-metadata.sh images

    # Images remain in Docker daemon for deploy:green to use (same runner, same daemon)
    - echo "Images built and ready in Docker daemon for deployment"
  only:
    - branches
    - merge_requests

# ============================================================================
# DURABLE INFRASTRUCTURE STAGE
# ============================================================================

durable:setup-ci:
  stage: durable
  tags:
    - docker-local
  before_script:
    - apk add --no-cache bash curl docker-cli-compose unzip
    - *install_terraform
    - *setup_scripts
  # NOTE: Durable infrastructure is independent of Docker image builds
  # It can run in parallel with build:docker-images since it only sets up database & LocalStack
  # But it must wait for build:dependencies to succeed to ensure the pipeline is valid
  dependencies:
    - validate:env-check
  needs:
    - validate:env-check
    - build:dependencies
  script:
    - |
      echo "=========================================="
      echo "Setting up CI Durable Infrastructure"
      echo "=========================================="
      echo ""

      # Diagnostic info to detect multi-runner issues
      echo "DIAGNOSTIC: Runner Info"
      echo "  Hostname: $(hostname)"
      echo "  Docker host: ${DOCKER_HOST:-unix:///var/run/docker.sock}"
      docker info 2>&1 | grep -E "Name:|ID:" | sed 's/^/  /'
      echo ""

      echo "This job is IDEMPOTENT:"
      echo "  - If database exists and is running: skips creation"
      echo "  - If database exists but stopped: starts it"
      echo "  - If database doesn't exist: creates it"
      echo ""
      echo "The CI database persists across pipeline runs for data continuity."
      echo "To rebuild: manually run 'teardown:durable-ci' job first"
      echo ""

      source .env
      echo "Configuring environment for CI..."
      sed -i 's|DB_HOST=.*|DB_HOST=echobase-ci-durable-mariadb|g' .env
      echo "DB_HOST=$(grep DB_HOST .env)"
      
      chmod +x durable/setup.sh durable/teardown.sh
      echo ""
      echo "Running durable infrastructure setup (idempotent)..."
      ./durable/setup.sh ci
      
      echo ""
      echo "Verifying durable infrastructure status..."
      docker ps --filter "name=echobase-ci-durable" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
      
      echo ""
      echo "Durable infrastructure ready for CI deployments"
  artifacts:
    paths:
      - .env
    expire_in: 1 hour
  only:
    - branches

# ============================================================================
# DETECT TARGET ENVIRONMENT
# ============================================================================


# ============================================================================
# TARGET ENVIRONMENT TESTS (run against deployed target environment)
# ============================================================================

test:target-api-gateway:
  stage: test
  tags:
    - docker-local
  before_script:
    - apk add --no-cache bash curl git nodejs npm docker-cli-compose
    - *setup_scripts
  <<: *cache_node_modules
  dependencies:
    - build:dependencies
    - validate:env-check
    - deploy:target
  needs:
    - build:dependencies
    - validate:env-check
    - deploy:target
  script:
    - |
      # Query nginx to determine which environment was deployed
      DEPLOY_TARGET=$(scripts/detect-target-environment.sh)
      echo ""
      echo "=========================================="
      echo "  TEST TARGET: $DEPLOY_TARGET"
      echo "=========================================="
      echo ""
      echo "Running all API Gateway tests (unit + security) against $DEPLOY_TARGET environment..."
      source .env

      # Set environment-specific port variables with correct names for the container
      if [ "$DEPLOY_TARGET" = "blue" ]; then
        ENV_FRONTEND_PORT=${BLUE_FRONTEND_PORT:-3544}
        ENV_VAR_NAME="BLUE_FRONTEND_PORT"
      else
        ENV_FRONTEND_PORT=${GREEN_FRONTEND_PORT:-3543}
        ENV_VAR_NAME="GREEN_FRONTEND_PORT"
      fi

      echo "Checking $DEPLOY_TARGET environment status..."
      docker ps --filter "name=echobase-$DEPLOY_TARGET" --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"
      scripts/wait-for-services.sh echobase-$DEPLOY_TARGET api-gateway

      # Get actual container name (works without compose file context)
      API_CONTAINER=$(scripts/get-container-name.sh echobase-$DEPLOY_TARGET api-gateway)
      echo "Running tests in container: $API_CONTAINER"
      docker exec -e ${ENV_VAR_NAME}=${ENV_FRONTEND_PORT} "$API_CONTAINER" npm test -- --coverage --ci
      mkdir -p backend/api-gateway/coverage backend/api-gateway/test-results
      echo "Copying test results and coverage from container..."
      docker cp "$API_CONTAINER":/app/coverage/. backend/api-gateway/coverage/ 2>/dev/null || echo "No coverage files found in container"
      docker cp "$API_CONTAINER":/app/junit.xml backend/api-gateway/junit.xml 2>/dev/null || echo "No junit.xml found in container"
  artifacts:
    reports:
      junit: backend/api-gateway/junit.xml
      coverage_report:
        coverage_format: cobertura
        path: backend/api-gateway/coverage/cobertura-coverage.xml
    paths:
      - backend/api-gateway/coverage/
      - backend/api-gateway/junit.xml
    expire_in: 1 week
    when: always
  after_script:
    - DEPLOY_TARGET=$(scripts/detect-target-environment.sh 2>/dev/null || echo "unknown")
    - API_CONTAINER=$(scripts/get-container-name.sh echobase-$DEPLOY_TARGET api-gateway 2>/dev/null) && docker logs --tail=50 "$API_CONTAINER" || true
  only:
    - branches
    - merge_requests

test:target-e2e:
  stage: test
  # Use host Docker daemon to access containers from deploy:target
  tags:
    - docker-local
  before_script:
    - apk add --no-cache bash curl git docker-cli-compose
    - *setup_scripts
  dependencies:
    - build:dependencies
    - validate:env-check
    - deploy:target
  needs:
    - build:dependencies
    - validate:env-check
    - deploy:target
  script:
    - |
      set -e

      # Error trapping to identify where failures occur
      failure_message() {
        echo "ERROR: Script failed on line $1"
      }
      trap 'failure_message $LINENO' ERR
      
      # Query nginx to determine which environment was deployed
      DEPLOY_TARGET=$(scripts/detect-target-environment.sh)
      echo ""
      echo "=========================================="
      echo "  TEST TARGET: $DEPLOY_TARGET"
      echo "=========================================="
      echo ""
      echo "Running E2E tests against $DEPLOY_TARGET environment..."
      source .env

      echo "Retrieving database credentials from Secrets Manager..."
      SECRET_JSON=$(docker exec echobase-ci-durable-localstack awslocal secretsmanager get-secret-value \
        --secret-id echobase/database/credentials \
        --query SecretString \
        --output text)

      export DB_USER=$(echo "$SECRET_JSON" | grep -o '"username":"[^"]*"' | cut -d'"' -f4)
      export DB_PASSWORD=$(echo "$SECRET_JSON" | grep -o '"password":"[^"]*"' | cut -d'"' -f4)
      export DB_NAME=$(echo "$SECRET_JSON" | grep -o '"dbname":"[^"]*"' | cut -d'"' -f4)

      echo "Database user: $DB_USER"
      echo "Database name: $DB_NAME"
      echo "Checking $DEPLOY_TARGET environment status..."
      docker compose -p echobase-$DEPLOY_TARGET ps
      scripts/wait-for-services.sh echobase-$DEPLOY_TARGET api-gateway frontend

      echo "=== Verifying Build Metadata in Running Containers ==="
      scripts/verify-build-metadata.sh containers echobase-$DEPLOY_TARGET || echo "WARNING: Build metadata verification failed (non-blocking)"

      echo "=== API Gateway Startup Logs (first 100 lines) ==="
      if API_GATEWAY_CONTAINER=$(scripts/get-container-name.sh echobase-$DEPLOY_TARGET api-gateway); then
        timeout 30 docker logs "$API_GATEWAY_CONTAINER" 2>&1 | head -100 || echo "WARNING: Failed to get first 100 lines (timeout or error)"
        echo ""
        echo "=== API Gateway Recent Logs (last 50 lines) ==="
        timeout 30 docker logs "$API_GATEWAY_CONTAINER" --tail 50 2>&1 || echo "WARNING: Failed to get last 50 lines (timeout or error)"
        echo "=== Log collection completed ==="
      else
        echo "WARNING: Failed to get API Gateway container (see error details above)"
      fi

      echo "Running Playwright E2E tests inside the $DEPLOY_TARGET network..."

      echo "Checking Docker networks..."
      docker network ls | grep $DEPLOY_TARGET || echo "No $DEPLOY_TARGET network found by name"

      # Use the exact network name from docker-compose file
      NETWORK_NAME="echobase-$DEPLOY_TARGET-network"

      # Verify the network exists
      if ! docker network inspect "$NETWORK_NAME" >/dev/null 2>&1; then
        echo "ERROR: Network $NETWORK_NAME not found. Available networks:"
        docker network ls
        exit 1
      fi

      echo "Using network: $NETWORK_NAME"

      echo "Creating test container..."
      CONTAINER_ID=$(docker create \
        --network "$NETWORK_NAME" \
        -e CI=true \
        -e DB_HOST=echobase-ci-durable-mariadb \
        -e DB_PORT=3306 \
        -e DB_NAME=$DB_NAME \
        -e DB_USER=$DB_USER \
        -e DB_PASSWORD=$DB_PASSWORD \
        -e API_BASE_URL=https://echobase-$DEPLOY_TARGET-api-gateway:3001 \
        -e WEB_BASE_URL=https://echobase-$DEPLOY_TARGET-frontend:443 \
        -e AWS_REGION=us-east-1 \
        -e AWS_ACCESS_KEY_ID=$AWS_ACCESS_KEY_ID \
        -e AWS_SECRET_ACCESS_KEY=$AWS_SECRET_ACCESS_KEY \
        -e SQS_ENDPOINT=http://echobase-$DEPLOY_TARGET-localstack:4566 \
        -e NODE_TLS_REJECT_UNAUTHORIZED=0 \
        -w /work \
        mcr.microsoft.com/playwright:v1.56.0-noble \
        /bin/bash -c "npx playwright install chromium && npm test")

      if [ -z "$CONTAINER_ID" ]; then
        echo "ERROR: Failed to create container"
        exit 1
      fi

      echo "Container created: $CONTAINER_ID"

      echo "Connecting test container to durable CI network..."
      docker network connect echobase-ci-durable-network $CONTAINER_ID

      echo "Copying test files into container..."
      if ! docker cp e2e-tests/. $CONTAINER_ID:/work/; then
        echo "ERROR: Failed to copy test files"
        docker rm $CONTAINER_ID || true
        exit 1
      fi

      echo "Removing .env file (CI uses environment variables instead)..."
      docker exec $CONTAINER_ID rm -f /work/.env || echo "No .env file to remove"

      echo "Starting tests..."
      set +e
      docker start -a $CONTAINER_ID
      TEST_EXIT_CODE=$?
      set -e

      echo "Tests completed with exit code: $TEST_EXIT_CODE"

      echo "Copying test results back..."
      mkdir -p e2e-tests/playwright-report e2e-tests/test-results
      docker cp $CONTAINER_ID:/work/playwright-report/. e2e-tests/playwright-report/ 2>&1 || echo "No playwright-report directory found"
      docker cp $CONTAINER_ID:/work/test-results/. e2e-tests/test-results/ 2>&1 || echo "No test-results directory found"

      if [ $TEST_EXIT_CODE -ne 0 ]; then
        echo "ERROR: Tests failed with exit code: $TEST_EXIT_CODE"
        echo ""
        echo "=== Container logs (last 50 lines) ==="
        docker logs --tail=50 $CONTAINER_ID || true
        echo "=== API Gateway Logs (last 100 lines) ==="
        docker logs echobase-$DEPLOY_TARGET-api-gateway --tail 100 2>&1 | grep -E "CSRF|CORS|403|ERROR|Rejected" || docker logs echobase-$DEPLOY_TARGET-api-gateway --tail 100
        echo ""
        echo "=== Frontend Logs (last 50 lines) ==="
        docker logs echobase-$DEPLOY_TARGET-frontend --tail 50 2>&1 || true
      else
        echo "✓ All E2E tests passed"
      fi

      echo "Removing container..."
      docker rm $CONTAINER_ID || true
      exit $TEST_EXIT_CODE

  artifacts:
    paths:
      - e2e-tests/playwright-report/
      - e2e-tests/test-results/
    reports:
      junit: e2e-tests/test-results/junit.xml
    expire_in: 1 week
    when: always
  after_script:
    - DEPLOY_TARGET=$(scripts/detect-target-environment.sh 2>/dev/null || echo "unknown")
    - echo "=== $DEPLOY_TARGET environment service logs (last 100 lines each) ==="
    - |
      for container in $(docker ps --filter "name=echobase-$DEPLOY_TARGET" --format "{{.Names}}" 2>/dev/null); do
        echo "=== Logs for $container ===" && docker logs --tail=100 "$container" 2>&1 || true
      done
  only:
    - branches
    - merge_requests

# ============================================================================
# DEPLOY STAGE
# ============================================================================

# ============================================================================
# BLUE-GREEN DEPLOYMENT
# ============================================================================

deploy:target:
  stage: deploy-target
  # Use host Docker daemon for persistent containers
  # Requires GitLab runner with Docker socket access
  tags:
    - docker-local
  before_script:
    - apk add --no-cache bash curl git docker-cli-compose wget unzip
    - *install_terraform
    - *setup_scripts
  dependencies:
    - durable:setup-ci
  needs:
    - build:docker-images
    - durable:setup-ci
  resource_group: deployment  # Prevent concurrent deployments
  script:
    - |
      echo "=========================================="
      echo "DEPLOY:TARGET - Environment Detection"
      echo "=========================================="
      echo ""
      echo "Checking environment setup..."
      echo "  Working directory: $(pwd)"
      echo "  Script exists: $(test -f scripts/detect-target-environment.sh && echo 'yes' || echo 'no')"
      echo "  Script executable: $(test -x scripts/detect-target-environment.sh && echo 'yes' || echo 'no')"
      echo ""

      # Diagnostic info to detect multi-runner issues
      echo "=========================================="
      echo "DIAGNOSTIC: Runner and Docker Info"
      echo "=========================================="
      echo "  Hostname: $(hostname)"
      echo "  Docker host: ${DOCKER_HOST:-unix:///var/run/docker.sock}"
      echo "  Docker info:"
      docker info 2>&1 | grep -E "Name:|ID:|Server Version:" | sed 's/^/    /'
      echo ""
      echo "  All running containers:"
      docker ps --format "    {{.Names}} ({{.Status}})" || echo "    ERROR: docker ps failed"
      echo ""
      echo "  Durable containers specifically:"
      docker ps --filter "name=echobase-ci-durable" --format "    {{.Names}} ({{.Status}})" || echo "    None found"
      echo "=========================================="
      echo ""

      # Detect target by querying nginx load balancer (single source of truth)
      echo "Detecting deployment target..."
      echo ""
      if ! DEPLOY_TARGET=$(scripts/detect-target-environment.sh); then
        echo ""
        echo "=========================================="
        echo "ERROR: Failed to detect target environment"
        echo "=========================================="
        echo "The detect-target-environment.sh script failed."
        echo "This determines which environment (blue or green) to deploy to."
        echo ""
        echo "If durable containers are missing, jobs may be running on different runners."
        echo "Ensure only ONE GitLab runner has the 'docker-local' tag."
        echo ""
        echo "Please check the diagnostic info and error messages above."
        echo ""
        exit 1
      fi

      echo ""
      echo "=========================================="
      echo "  DEPLOY TARGET: $DEPLOY_TARGET"
      echo "=========================================="
      echo ""

      source .env

      # Note: CORS_ORIGIN is defined in docker-compose.{blue,green}.yml, not in base file
      # Each environment has its own allowed origins (localhost ports + internal container names)

      # Set environment-specific variables
      if [ "$DEPLOY_TARGET" = "blue" ]; then
        ENV_API_PORT=${BLUE_API_PORT:-3102}
        ENV_FRONTEND_PORT=${BLUE_FRONTEND_PORT:-3544}
        ENV_LOCALSTACK_PORT=${BLUE_LOCALSTACK_PORT:-4667}
      else
        ENV_API_PORT=${GREEN_API_PORT:-3101}
        ENV_FRONTEND_PORT=${GREEN_FRONTEND_PORT:-3543}
        ENV_LOCALSTACK_PORT=${GREEN_LOCALSTACK_PORT:-4666}
      fi

      echo "Verifying durable infrastructure is running..."
      docker ps --filter "name=echobase-ci-durable" --format "{{.Names}}: {{.Status}}"

      echo "Cleaning up any existing $DEPLOY_TARGET environment..."
      docker compose -f docker-compose.yml -f docker-compose.$DEPLOY_TARGET.yml -p echobase-$DEPLOY_TARGET down || true

      echo "Note: Database is managed separately in durable infrastructure"

      # Images are already in Docker daemon from build:docker-images (same runner)
      echo "Verifying images are available in Docker daemon..."
      docker images | grep echobase
      scripts/verify-build-metadata.sh images

      echo "Images ready for deployment (built in build:docker-images job)"

      echo "Starting $DEPLOY_TARGET environment..."
      docker compose -f docker-compose.yml -f docker-compose.$DEPLOY_TARGET.yml -p echobase-$DEPLOY_TARGET up -d localstack

      scripts/wait-for-services.sh echobase-$DEPLOY_TARGET localstack
      scripts/wait-for-endpoint.sh http://localhost:${ENV_LOCALSTACK_PORT}/_localstack/health ${LOCALSTACK_TIMEOUT} "LocalStack ($DEPLOY_TARGET)"

      # Apply infrastructure changes (e.g., S3 buckets, queues) to LocalStack
      scripts/terraform-apply.sh http://localhost:${ENV_LOCALSTACK_PORT}

      echo ""
      echo "Starting application services..."
      echo "  Note: Frontend depends on API Gateway being healthy"
      echo "  This may take up to 2 minutes while health checks run"
      echo ""

      # Start api-gateway first without frontend to avoid dependency failures
      echo "Step 1: Starting API Gateway and Order Processor..."
      if ! docker compose -f docker-compose.yml -f docker-compose.$DEPLOY_TARGET.yml -p echobase-$DEPLOY_TARGET up -d api-gateway order-processor; then
        echo ""
        echo "=========================================="
        echo "ERROR: Failed to start API Gateway or Order Processor"
        echo "=========================================="
        docker compose -p echobase-$DEPLOY_TARGET ps
        docker compose -p echobase-$DEPLOY_TARGET logs --tail=100 api-gateway
        docker compose -p echobase-$DEPLOY_TARGET logs --tail=100 order-processor
        exit 1
      fi

      echo ""
      echo "Step 2: Waiting for API Gateway to become healthy..."
      if ! scripts/wait-for-services.sh echobase-$DEPLOY_TARGET api-gateway order-processor; then
        echo ""
        echo "=========================================="
        echo "ERROR: API Gateway or Order Processor failed health check"
        echo "=========================================="
        echo "This usually means:"
        echo "  1. Database connection failed"
        echo "  2. Secrets Manager credentials are incorrect"
        echo "  3. Environment variables are missing"
        echo "  4. Application crashed on startup"
        echo ""
        echo "Check the logs above for specific error messages."
        exit 1
      fi

      echo ""
      echo "Step 3: Starting Frontend (depends on API Gateway)..."
      docker compose -f docker-compose.yml -f docker-compose.$DEPLOY_TARGET.yml -p echobase-$DEPLOY_TARGET up -d frontend

      echo ""
      echo "Step 4: Waiting for Frontend to become healthy..."
      scripts/wait-for-services.sh echobase-$DEPLOY_TARGET frontend

      echo "Verifying $DEPLOY_TARGET environment..."
      docker compose -p echobase-$DEPLOY_TARGET ps

      echo ""
      echo "=== Port Mappings Check ==="
      docker ps --format "table {{.Names}}\t{{.Ports}}" | grep -E "echobase-$DEPLOY_TARGET|echobase-ci-durable|NAMES"

      echo "✓ $DEPLOY_TARGET environment deployed successfully!"
      echo "$DEPLOY_TARGET environment services are running on internal network:"
      echo "  - MariaDB (Durable): echobase-ci-durable-mariadb:3306"
      echo "  - LocalStack: echobase-$DEPLOY_TARGET-localstack:4566"
      echo "  - API Gateway: echobase-$DEPLOY_TARGET-api-gateway:3001"
      echo "  - Frontend: echobase-$DEPLOY_TARGET-frontend:443"
      echo ""
      echo "External access ports:"
      echo "  - API Gateway: localhost:$ENV_API_PORT"
      echo "  - Frontend: localhost:$ENV_FRONTEND_PORT"

      echo ""
      echo "=== Network Connectivity Verification ==="
      echo "Containers on echobase-ci-durable-network:"
      docker network inspect echobase-ci-durable-network --format '{{range .Containers}}  {{.Name}}{{println}}{{end}}' 2>/dev/null || echo "  (failed to inspect)"
      echo ""
      echo "Testing nginx -> $DEPLOY_TARGET connectivity:"
      NGINX_CONTAINER=$(docker ps --filter "label=echobase.service=nginx" --format "{{.Names}}" | head -1)
      if [ -n "$NGINX_CONTAINER" ]; then
        echo -n "  nginx -> frontend: "
        docker exec "$NGINX_CONTAINER" wget -q --spider --timeout=5 --no-check-certificate "https://echobase-${DEPLOY_TARGET}-frontend:443/" 2>/dev/null && echo "OK" || echo "FAIL"
        echo -n "  nginx -> api-gateway: "
        docker exec "$NGINX_CONTAINER" wget -q --spider --timeout=5 --no-check-certificate "https://echobase-${DEPLOY_TARGET}-api-gateway:3001/health" 2>/dev/null && echo "OK" || echo "FAIL"
      else
        echo "  WARNING: nginx container not found"
      fi
      echo ""

      echo "$DEPLOY_TARGET environment ready for testing (containers will persist)"
      echo "Note: Database is in durable infrastructure and persists across deployments"
  after_script:
    - |
      # Capture logs on failure for debugging
      # Detect which environment was being deployed (may not be set if detection failed)
      if [ -n "$DEPLOY_TARGET" ]; then
        echo ""
        echo "=========================================="
        echo "DEBUG: Showing $DEPLOY_TARGET container logs"
        echo "=========================================="
        echo ""
        echo "=== Container Status ==="
        docker compose -p echobase-$DEPLOY_TARGET ps 2>&1 || echo "Failed to get container status"
        echo ""
        echo "=== API Gateway Logs (last 100 lines) ==="
        docker compose -p echobase-$DEPLOY_TARGET logs --tail=100 api-gateway 2>&1 || echo "Failed to get api-gateway logs"
        echo ""
        echo "=== Frontend Logs (last 50 lines) ==="
        docker compose -p echobase-$DEPLOY_TARGET logs --tail=50 frontend 2>&1 || echo "Failed to get frontend logs"
        echo ""
        echo "=== LocalStack Logs (last 50 lines) ==="
        docker compose -p echobase-$DEPLOY_TARGET logs --tail=50 localstack 2>&1 || echo "Failed to get localstack logs"
        echo ""
        echo "=== Durable Infrastructure Status ==="
        docker ps --filter "name=echobase-ci-durable" --format "table {{.Names}}\t{{.Status}}" 2>&1 || echo "Failed to get durable status"
      fi
  only:
    - branches

promote:to-production:
  stage: promote
  tags:
    - docker-local  # Required to access Docker socket for nginx queries
  before_script:
    - apk add --no-cache bash docker-cli-compose curl
    - chmod +x scripts/*.sh
  needs:
    - test:target-api-gateway
    - test:target-e2e
  script:
    - |
      # Query nginx to determine which environment to promote
      DEPLOY_TARGET=$(scripts/detect-target-environment.sh)
      echo "Promoting $DEPLOY_TARGET to production with smoke tests..."

      # Use promote-with-tests.sh which handles:
      # 1. Traffic switch
      # 2. Smoke tests (with 2 retries)
      # 3. Automatic rollback on failure
      ./scripts/promote-with-tests.sh $DEPLOY_TARGET

      echo ""
      echo "Production now points to: $DEPLOY_TARGET"
      if [ "$DEPLOY_TARGET" = "blue" ]; then
        echo "Previous green environment still running for rollback"
        echo "Use 'teardown:green' job to remove it when confident"
      else
        echo "Previous blue environment still running for rollback"
        echo "Use 'teardown:blue' job to remove it when confident"
      fi
  environment:
    name: production
    url: https://localhost
  when: manual
  only:
    - branches

rollback:to-previous:
  stage: promote
  tags:
    - docker-local  # Required to access Docker socket for nginx queries
  before_script:
    - apk add --no-cache bash docker-cli-compose
    - chmod +x scripts/*.sh
  needs: []
  script:
    - |
      echo "Rolling back to previous environment..."

      # Get current production environment from nginx
      CURRENT=$(./scripts/get-active-environment.sh)
      echo "Current production (from nginx): $CURRENT"

      # Determine rollback target
      if [ "$CURRENT" = "blue" ]; then
        ROLLBACK_TARGET="green"
      elif [ "$CURRENT" = "green" ]; then
        ROLLBACK_TARGET="blue"
      else
        echo "ERROR: No production environment detected in nginx config"
        exit 1
      fi

      echo "Rolling back to: $ROLLBACK_TARGET"

      # Use switch-traffic.sh to perform the rollback
      ./scripts/switch-traffic.sh $ROLLBACK_TARGET

      echo "✓ Successfully rolled back to $ROLLBACK_TARGET environment"
  environment:
    name: production
    url: https://localhost
  when: manual
  only:
    - branches

# ============================================================================
# TEARDOWN STAGE
# ============================================================================

teardown:blue:
  stage: teardown
  tags:
    - docker-local  # Required for Docker access and nginx queries
  needs: []
  before_script:
    - apk add --no-cache bash docker-cli-compose
    - *setup_scripts
  script:
    - |
      echo "Removing BLUE environment..."

      # Safety check: Do not teardown production (query nginx - REQUIRED)
      PRODUCTION_ENV=$(scripts/get-active-environment.sh)
      if [ "$PRODUCTION_ENV" = "blue" ]; then
        echo "ERROR: Cannot teardown blue - it is currently production (per nginx)!"
        echo "Switch traffic to green first using rollback:to-previous"
        exit 1
      fi
      echo "Safety check passed: production is '$PRODUCTION_ENV', not blue"

      echo "Tearing down blue environment..."
      docker compose -f docker-compose.yml -f docker-compose.blue.yml -p echobase-blue down || true
      echo "✓ Blue environment removed"
      echo "Note: Durable CI infrastructure is still running."
  when: manual
  only:
    - branches

teardown:green:
  stage: teardown
  tags:
    - docker-local  # Required for Docker access and nginx queries
  needs: []
  before_script:
    - apk add --no-cache bash docker-cli-compose
    - *setup_scripts
  script:
    - |
      echo "Removing GREEN environment..."

      # Safety check: Do not teardown production (query nginx - REQUIRED)
      PRODUCTION_ENV=$(scripts/get-active-environment.sh)
      if [ "$PRODUCTION_ENV" = "green" ]; then
        echo "ERROR: Cannot teardown green - it is currently production (per nginx)!"
        echo "Switch traffic to blue first using rollback:to-previous"
        exit 1
      fi
      echo "Safety check passed: production is '$PRODUCTION_ENV', not green"

      echo "Tearing down green environment..."
      docker compose -f docker-compose.yml -f docker-compose.green.yml -p echobase-green down || true
      echo "✓ Green environment removed"
      echo "Note: Durable CI infrastructure is still running. Use teardown:durable-ci to remove it."
  when: manual
  only:
    - branches

teardown:durable-ci:
  stage: teardown
  needs: []
  before_script:
    - apk add --no-cache bash docker-cli-compose
    - *setup_scripts
  script:
    - |
      echo "WARNING: This will remove the CI durable infrastructure!"
      echo "This includes the CI database and all its data."
      chmod +x durable/teardown.sh
      ./durable/teardown.sh ci --volumes
      echo "CI durable infrastructure removed (including data)"
  when: manual
  only:
    - branches

teardown:devlocal:
  stage: teardown
  needs: []
  <<: *terraform_job_setup
  script:
    - echo "Cleaning up devlocal environment..."
    - echo "NOTE - This cleans the devlocal environment started with start.sh"
    - echo "       For green staging environment, use cleanup:green"
    - scripts/terraform-destroy.sh
    - docker compose down
    - echo "Dev-local cleanup complete!"
  environment:
    name: devlocal
    action: stop
  when: manual
  only:
    - branches

teardown:volumes:
  stage: teardown
  needs: []
  <<: *terraform_job_setup
  script:
    - echo "WARNING - This will remove all Docker volumes and data!"
    - scripts/terraform-destroy.sh
    - docker compose down -v
    - echo "All volumes removed!"
  when: manual
  only:
    - branches

# ============================================================================
# UTILITY JOBS
# ============================================================================

logs:view:
  stage: .post
  script:
    - echo "Fetching logs from running containers..."
    - docker compose ps
    - echo "=== API Gateway Logs ==="
    - docker compose logs --tail=50 api-gateway || true
    - echo "=== Order Processor Logs ==="
    - docker compose logs --tail=50 order-processor || true
    - echo "=== Frontend Logs ==="
    - docker compose logs --tail=50 frontend || true
    - echo "=== Localstack Logs ==="
    - docker compose logs --tail=50 localstack || true
  when: manual
  only:
    - branches

database:query:
  stage: .post
  tags:
    - docker-local
  script:
    - echo "Querying CI database for recent orders..."
    - source .env
    - docker exec echobase-ci-durable-mariadb mariadb -u $DB_USER -p$DB_PASSWORD $DB_NAME -e "SELECT id, customer_name, product_name, order_status, created_at FROM orders ORDER BY created_at DESC LIMIT 10;"
  when: manual
  only:
    - branches
